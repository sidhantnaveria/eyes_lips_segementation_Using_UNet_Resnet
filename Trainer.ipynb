{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "TrainerUnet_Resnet34.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "6c1WMR3ve7am"
      },
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import functools\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from model import ModelClass"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJepn8MDq8yz"
      },
      "source": [
        "def dice_loss(pred, target):\n",
        "    \"\"\"This definition generalize to real valued pred and target vector.\n",
        "This should be differentiable.\n",
        "    pred: tensor with first dimension as batch\n",
        "    target: tensor with first dimension as batch\n",
        "    \"\"\"\n",
        "\n",
        "    smooth = 1.\n",
        "\n",
        "    # have to use contiguous since they may from a torch.view op\n",
        "    iflat = pred.contiguous().view(-1)\n",
        "    tflat = target.contiguous().view(-1)\n",
        "    intersection = (iflat * tflat).sum()\n",
        "\n",
        "    A_sum = torch.sum(tflat * iflat)\n",
        "    B_sum = torch.sum(tflat * tflat)\n",
        "    \n",
        "    return 1- ((2. * intersection + smooth) / (A_sum + B_sum + smooth) )"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yp2gMVLDTDY"
      },
      "source": [
        "EPS = 1e-6\n",
        "#slightly modified\n",
        "def get_IoU(outputs, labels):\n",
        "    outputs = outputs.int()\n",
        "    labels = labels.int()\n",
        "    # Taken from: https://www.kaggle.com/iezepov/fast-iou-scoring-metric-in-pytorch-and-numpy\n",
        "    intersection = (outputs & labels).float().sum((1, 2))  # Will be zero if Truth=0 or Prediction=0\n",
        "    union = (outputs | labels).float().sum((1, 2))  # Will be zero if both are 0\n",
        "\n",
        "    iou = (intersection + EPS) / (union + EPS)  # We smooth our devision to avoid 0/0\n",
        "\n",
        "    # thresholded = torch.clamp(20 * (iou - 0.5), 0, 10).ceil() / 10  # This is equal to comparing with thresolds\n",
        "    # return thresholded.mean()  # Or thresholded.mean() if you are interested in average across the batch\n",
        "    return iou.mean()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NH4VR9xFMQay"
      },
      "source": [
        "## Training model\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn import init\n",
        "import functools\n",
        "import torch.optim as optim\n",
        "from torch.autograd import Variable\n",
        "import numpy as np\n",
        "from model import ModelClass\n",
        "\n",
        "\n",
        "X = np.load(\"/content/drive/MyDrive/Images.npy\")\n",
        "Y = np.load(\"/content/drive/MyDrive/Masks.npy\")\n",
        "X=X.astype('float32')\n",
        "# print(X.dtype)\n",
        "# print(np.mean(X).dtype)\n",
        "mean = np.mean(X)  # mean for data centering\n",
        "std = np.std(X)  # std for data normalization\n",
        "\n",
        "X -= mean  \n",
        "X /= std\n",
        "\n",
        "Y = np.where(Y > 1, 1, 0)\n",
        "\n",
        "X_train=X[:1900]\n",
        "Y_train=Y[:1900]\n",
        "X_test=X[1900:]\n",
        "Y_test=Y[1900:]\n",
        "\n",
        "\n",
        "model=ModelClass().cuda()\n",
        "\n",
        "lr = 3.00000002e-03 # 0.1\n",
        "criterion = nn.BCELoss() #nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.SGD(model.parameters(), lr=lr, momentum=0.8, nesterov=True, weight_decay=0.0003)\n",
        "\n",
        "is_train = True\n",
        "is_pretrain = False\n",
        "\n",
        "total_epoch = 25\n",
        "if is_train is True:\n",
        "\n",
        "  if is_pretrain == True:\n",
        "    model.load_state_dict((torch.load('/content/drive/MyDrive/Unet_resnet4.pkl')))\n",
        "  \n",
        "    \n",
        "  \n",
        "  for epoch in range(total_epoch):\n",
        "      model.train()\n",
        "      lossavg=0\n",
        "      tot=0\n",
        "      for inp,msk in zip(X_train,Y_train):\n",
        "          # inp.astype(np.float32)\n",
        "          # msk.astype(np.int32)\n",
        "\n",
        "\n",
        "          input = Variable(torch.from_numpy(inp).type(torch.float32).cuda())\n",
        "          \n",
        "          mask = Variable(torch.from_numpy(msk).type(torch.float32).cuda())\n",
        "\n",
        "          # Forward + Backward + Optimize\n",
        "          optimizer.zero_grad()\n",
        "          outputs = model(input.permute(2,0,1).unsqueeze(0))\n",
        "          # cost=get_IoU(outputs, mask.permute(2,0,1).unsqueeze(0))\n",
        "          \n",
        "          # loss = Variable(cost.data, requires_grad=True)\n",
        "          loss = dice_loss(outputs, mask.permute(2,0,1).unsqueeze(0)) #\n",
        "          # loss = criterion(outputs, mask.permute(2,0,1).unsqueeze(0))\n",
        "          loss.backward()\n",
        "          # print(loss)\n",
        "          optimizer.step()\n",
        "          \n",
        "          lossavg +=loss.item()\n",
        "          tot+=1\n",
        "          \n",
        "      aver=lossavg/tot\n",
        "      print(\" \")\n",
        "      \n",
        "      \n",
        "      print(\"Epoch [%d/%d],  AVERAGELoss: %.4f\" %(epoch+1,total_epoch,aver))\n",
        "      print('evaluate test set:')\n",
        "      \n",
        "      # # Decaying Learning Rate\n",
        "      if (epoch+1) / float(total_epoch) == 0.3 or (epoch+1) / float(total_epoch) == 0.6 or (epoch+1) / float(total_epoch) == 0.9:\n",
        "          lr /= 10\n",
        "          print('reset learning rate to:', lr)\n",
        "          for param_group in optimizer.param_groups:\n",
        "              param_group['lr'] = lr\n",
        "              print(param_group['lr'])\n",
        "          # optimizer = torch.optim.Adam(model.parameters(), lr=lr)\n",
        "          # optim.SGD(model.parameters(), lr=lr, momentum=0.9, nesterov=True, weight_decay=0.0001)\n",
        "  # Save the Model\n",
        "  torch.save(model.state_dict(), '/content/drive/My Drive/Unet_resnet4.pkl')\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o-xMWryG3XeV"
      },
      "source": [
        "X = np.load(\"/content/drive/MyDrive/Images.npy\")\n",
        "Y = np.load(\"/content/drive/MyDrive/Masks.npy\")\n",
        "X=X.astype('float32')\n",
        "# print(X.dtype)\n",
        "# print(np.mean(X).dtype)\n",
        "mean = np.mean(X)  # mean for data centering\n",
        "std = np.std(X)  # std for data normalization\n",
        "\n",
        "X -= mean  \n",
        "X /= std\n",
        "\n",
        "Y = np.where(Y > 1, 1, 0)\n",
        "\n",
        "X_train=X[:1900]\n",
        "Y_train=Y[:1900]\n",
        "X_test=X[1900:]\n",
        "Y_test=Y[1900:]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B5VwSX1F3w75",
        "outputId": "1ce04991-84f0-4f71-f2f8-d8154ad48eec"
      },
      "source": [
        "loss_total=0\n",
        "for img,mask in zip(X_test,Y_test):\n",
        "  input = Variable(torch.from_numpy(img).type(torch.float32))\n",
        "          \n",
        "  msk = Variable(torch.from_numpy(mask).type(torch.float32))\n",
        "  device = torch.device(\"cpu\")\n",
        "  model=ModelClass().to(device)\n",
        "  \n",
        "  model.load_state_dict(torch.load(\"/content/drive/MyDrive/last_model_full.pkl\",map_location=torch.device('cpu')))\n",
        "  model.eval()\n",
        "\n",
        "  \n",
        "  outputs = model(input.permute(2,0,1).unsqueeze(0))\n",
        "  \n",
        "  loss = get_IoU(outputs, msk.permute(2,0,1).unsqueeze(0)) \n",
        "  print(loss)\n",
        "  loss_total +=loss\n",
        "print(\"Average IOU score for test set: \",loss_total/100)\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor(0.4034)\n",
            "tensor(0.3488)\n",
            "tensor(0.2079)\n",
            "tensor(0.0534)\n",
            "tensor(0.2041)\n",
            "tensor(0.1884)\n",
            "tensor(0.0596)\n",
            "tensor(0.3563)\n",
            "tensor(0.2936)\n",
            "tensor(0.0553)\n",
            "tensor(0.3366)\n",
            "tensor(0.2195)\n",
            "tensor(0.0946)\n",
            "tensor(0.2431)\n",
            "tensor(0.3837)\n",
            "tensor(0.1376)\n",
            "tensor(0.1731)\n",
            "tensor(0.1423)\n",
            "tensor(0.2435)\n",
            "tensor(0.2585)\n",
            "tensor(0.2244)\n",
            "tensor(0.2899)\n",
            "tensor(0.3953)\n",
            "tensor(0.3719)\n",
            "tensor(0.3680)\n",
            "tensor(0.1416)\n",
            "tensor(0.2625)\n",
            "tensor(0.3055)\n",
            "tensor(0.2545)\n",
            "tensor(0.3248)\n",
            "tensor(0.2506)\n",
            "tensor(0.0789)\n",
            "tensor(0.2392)\n",
            "tensor(0.0789)\n",
            "tensor(0.3405)\n",
            "tensor(0.2000)\n",
            "tensor(0.2510)\n",
            "tensor(0.2901)\n",
            "tensor(0.1691)\n",
            "tensor(0.3762)\n",
            "tensor(0.2664)\n",
            "tensor(0.4619)\n",
            "tensor(0.0841)\n",
            "tensor(0.0984)\n",
            "tensor(0.1452)\n",
            "tensor(0.5165)\n",
            "tensor(0.0754)\n",
            "tensor(0.1222)\n",
            "tensor(0.1062)\n",
            "tensor(0.5633)\n",
            "tensor(0.1343)\n",
            "tensor(0.1413)\n",
            "tensor(0.1455)\n",
            "tensor(0.4936)\n",
            "tensor(0.0480)\n",
            "tensor(0.1651)\n",
            "tensor(0.3602)\n",
            "tensor(0.2238)\n",
            "tensor(0.0669)\n",
            "tensor(0.1489)\n",
            "tensor(0.0633)\n",
            "tensor(0.3408)\n",
            "tensor(0.0478)\n",
            "tensor(0.3447)\n",
            "tensor(0.2195)\n",
            "tensor(0.3719)\n",
            "tensor(0.1453)\n",
            "tensor(0.1880)\n",
            "tensor(0.1651)\n",
            "tensor(0.4892)\n",
            "tensor(0.3564)\n",
            "tensor(0.3293)\n",
            "tensor(0.0561)\n",
            "tensor(0.4930)\n",
            "tensor(0.1805)\n",
            "tensor(0.1649)\n",
            "tensor(0.0827)\n",
            "tensor(0.1766)\n",
            "tensor(0.2826)\n",
            "tensor(0.1217)\n",
            "tensor(0.0476)\n",
            "tensor(0.2196)\n",
            "tensor(0.1494)\n",
            "tensor(0.2195)\n",
            "tensor(0.4587)\n",
            "tensor(0.2784)\n",
            "tensor(0.3017)\n",
            "tensor(0.1424)\n",
            "tensor(0.1573)\n",
            "tensor(0.0673)\n",
            "tensor(0.3487)\n",
            "tensor(0.3015)\n",
            "tensor(0.2358)\n",
            "tensor(0.1142)\n",
            "tensor(0.2038)\n",
            "tensor(0.2428)\n",
            "tensor(0.0555)\n",
            "tensor(0.1180)\n",
            "tensor(0.1180)\n",
            "tensor(0.0932)\n",
            "Average IOU score for test set:  tensor(0.2248)\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}